# Gradient-Descent


Implementation and visualization of Gradient descent Algorithm


Implement the following formulas, as explained in the text.

      Sigmoid activation function
      
            ğœ(ğ‘¥)=1/(1+ğ‘’âˆ’ğ‘¥)
 
      Output (prediction) formula
      
             ğ‘¦Ì‚ =ğœ(ğ‘¤1ğ‘¥1+ğ‘¤2ğ‘¥2+ğ‘)
 
      Error function
      
            ğ¸ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿ(ğ‘¦,ğ‘¦Ì‚ )=âˆ’ğ‘¦log(ğ‘¦Ì‚ )âˆ’(1âˆ’ğ‘¦)log(1âˆ’ğ‘¦Ì‚ )
 
      The function that updates the weights
      
          ğ‘¤ğ‘–âŸ¶ğ‘¤ğ‘–+ğ›¼(ğ‘¦âˆ’ğ‘¦Ì‚ )ğ‘¥ğ‘–
          ğ‘âŸ¶ğ‘+ğ›¼(ğ‘¦âˆ’ğ‘¦Ì‚ )


#Initial plot of data

![Test Image 1](initial.png)



#After Gradient Descent

![Test Image 1](final.png)


#Error rate graph

![Test Image 1](error.png)

